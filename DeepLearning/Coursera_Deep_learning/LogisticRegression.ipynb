{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LogisticRegression.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOgnrmu6j8zzuBRPOx7hd7H"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"KzfKWtSfO7iv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595481247533,"user_tz":-360,"elapsed":1766,"user":{"displayName":"Jobayed Ullah Shuvo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEb5dzZzsBsbJE-UM9AEEu3_vdtvDxQn1ABVaMnw=s64","userId":"01262328741808285025"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import h5py\n","import scipy\n","from PIL import Image\n","from scipy import ndimage\n","\n","%matplotlib inline"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"PpcaIBvBO8Xg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595481250530,"user_tz":-360,"elapsed":1633,"user":{"displayName":"Jobayed Ullah Shuvo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEb5dzZzsBsbJE-UM9AEEu3_vdtvDxQn1ABVaMnw=s64","userId":"01262328741808285025"}}},"source":["def sigmoid(z):\n","  \"\"\"\n","  Compute the sigmoid of z\n","\n","  Arguments:\n","  z -- A scalar or numpy array of any size.\n","\n","  Return:\n","  s -- sigmoid(z)\n","  \"\"\"\n","\n","  return 1/(1+np.exp(-z))\n","def initialize_with_zeros(dim):\n","  \"\"\"\n","  This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n","  \n","  Argument:\n","  dim -- size of the w vector we want (or number of parameters in this case)\n","  \n","  Returns:\n","  w -- initialized vector of shape (dim, 1)\n","  b -- initialized scalar (corresponds to the bias)\n","  \"\"\"\n","  \n","  ### START CODE HERE ### (≈ 1 line of code)\n","  w = np.zeros((dim,1))\n","  b = 0\n","  ### END CODE HERE ###\n","\n","  assert(w.shape == (dim, 1))\n","  assert(isinstance(b, float) or isinstance(b, int))\n","  \n","  return w, b\n","\n","def propagate(w, b, X, Y):\n","    \"\"\"\n","    Implement the cost function and its gradient for the propagation explained above\n","\n","    Arguments:\n","    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n","    b -- bias, a scalar\n","    X -- data of size (num_px * num_px * 3, number of examples)\n","    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)\n","\n","    Return:\n","    cost -- negative log-likelihood cost for logistic regression\n","    dw -- gradient of the loss with respect to w, thus same shape as w\n","    db -- gradient of the loss with respect to b, thus same shape as b\n","    \n","    Tips:\n","    - Write your code step by step for the propagation. np.log(), np.dot()\n","    \"\"\"\n","    \n","    m = X.shape[1]\n","    \n","    # FORWARD PROPAGATION (FROM X TO COST)\n","    ### START CODE HERE ### (≈ 2 lines of code)\n","    A    = sigmoid(np.dot(w.T,X)+b)                       # compute activation\n","    cost = -1/m*np.sum(Y*np.log(A)+(1-Y)*np.log(1-A))   # compute cost\n","    ### END CODE HERE ###\n","    \n","    # BACKWARD PROPAGATION (TO FIND GRAD)\n","    ### START CODE HERE ### (≈ 2 lines of code)\n","    dw = 1/m*np.dot(X,(A-Y).T)\n","    db = 1/m*np.sum(A-Y)\n","    ### END CODE HERE ###\n","\n","    assert(dw.shape == w.shape)\n","    assert(db.dtype == float)\n","    cost = np.squeeze(cost)\n","    assert(cost.shape == ())\n","    \n","    grads = {\"dw\": dw,\n","             \"db\": db}\n","    \n","    return grads, cost\n","\n","def predict(w, b, X):\n","    '''\n","    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n","    \n","    Arguments:\n","    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n","    b -- bias, a scalar\n","    X -- data of size (num_px * num_px * 3, number of examples)\n","    \n","    Returns:\n","    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n","    '''\n","    \n","    m = X.shape[1]\n","    Y_prediction = np.zeros((1,m))\n","    w = w.reshape(X.shape[0], 1)\n","    \n","    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n","    ### START CODE HERE ### (≈ 1 line of code)\n","    A = sigmoid(np.dot(w.T,X)+b)\n","    \n","    ### END CODE HERE ###\n","    \n","    for i in range(A.shape[1]):\n","        \n","        # Convert probabilities A[0,i] to actual predictions p[0,i]\n","        ### START CODE HERE ### (≈ 4 lines of code)\n","        \n","        Y_prediction[0][i] = 1. if A[0][i]>0.5 else 0.\n","        ### END CODE HERE ###\n","    \n","    assert(Y_prediction.shape == (1, m))\n","    \n","    return Y_prediction\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"JeHFmEocXg3u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1595481318623,"user_tz":-360,"elapsed":1159,"user":{"displayName":"Jobayed Ullah Shuvo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEb5dzZzsBsbJE-UM9AEEu3_vdtvDxQn1ABVaMnw=s64","userId":"01262328741808285025"}},"outputId":"5e76c66f-05ba-4bcf-fd7b-9d0f907d4a83"},"source":["A = np.random.randn(4,3)\n","B = np.sum(A, axis = 1, keepdims = True)\n","A,B.shape"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[ 0.06082623, -0.66335789,  0.41986237],\n","        [ 0.55384262, -0.31615154,  0.46190334],\n","        [-0.56501274, -1.79757232,  0.34894784],\n","        [-0.32276965, -1.64459347,  0.77938352]]), (4, 1))"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"-xudE2UdF3qq","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}